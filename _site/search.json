[
  {
    "objectID": "coursework.html",
    "href": "coursework.html",
    "title": "Coursework",
    "section": "",
    "text": "This page highlights the UCLA courses that shape my Statistics & Data Science background.\n\n\n\n\n\n\nCCAS 10A ‚Äì Chicano History & Culture\n\nSTATS 100A ‚Äì Introduction to Probability\n\nSTATS 20 ‚Äì Programming with R\n\n\n\n\n\n\nSTATS 100B ‚Äì Introduction to Mathematical Statistics\n\nSTATS 101A ‚Äì Introduction to Data Analysis and Regression\n\nSTATS 102A ‚Äì Introduction to Computational Statistics with R\n\n\n\n\n\n\nCOMM 188C ‚Äì Data Science for Social Good\n\nSTATS 100C ‚Äì Linear Models\n\nSTATS 102B ‚Äì Introduction to Computation & Optimization\n\n\n\n\n\n\nDGT HUM 101 ‚Äì Digital Humanities\n\nSTATS 101B ‚Äì Design & Analysis of Experiments\n\nSTATS 102C ‚Äì Monte Carlo Methods\n\n\n\n\n\n\n\n\n\nSTATS 101C ‚Äì Regression and Data Mining\n\nSTATS 140XP ‚Äì Statistics Consulting\n\n\n\n\n\n\nAF AMER 112A ‚Äì The Sunken Place\n\nFILM TV 183A ‚Äì Film & TV Development\n\nSTATS 141XP ‚Äì Statistics Consulting (Capstone sequence)\n\n\n\n\n\n\n\nStatistical Theory & Methods ‚Äì STATS 100A‚ÄìC, 101A‚ÄìC\n\nComputing & Optimization ‚Äì STATS 20, 102A‚ÄìC\n\nApplied & Consulting ‚Äì STATS 101B, 140XP, 141XP\n\nInterdisciplinary Work ‚Äì Data science for social good, digital humanities, film & media, and ethnic studies"
  },
  {
    "objectID": "coursework.html#completed-courses",
    "href": "coursework.html#completed-courses",
    "title": "Coursework",
    "section": "",
    "text": "CCAS 10A ‚Äì Chicano History & Culture\n\nSTATS 100A ‚Äì Introduction to Probability\n\nSTATS 20 ‚Äì Programming with R\n\n\n\n\n\n\nSTATS 100B ‚Äì Introduction to Mathematical Statistics\n\nSTATS 101A ‚Äì Introduction to Data Analysis and Regression\n\nSTATS 102A ‚Äì Introduction to Computational Statistics with R\n\n\n\n\n\n\nCOMM 188C ‚Äì Data Science for Social Good\n\nSTATS 100C ‚Äì Linear Models\n\nSTATS 102B ‚Äì Introduction to Computation & Optimization\n\n\n\n\n\n\nDGT HUM 101 ‚Äì Digital Humanities\n\nSTATS 101B ‚Äì Design & Analysis of Experiments\n\nSTATS 102C ‚Äì Monte Carlo Methods"
  },
  {
    "objectID": "coursework.html#in-progress-planned",
    "href": "coursework.html#in-progress-planned",
    "title": "Coursework",
    "section": "",
    "text": "STATS 101C ‚Äì Regression and Data Mining\n\nSTATS 140XP ‚Äì Statistics Consulting\n\n\n\n\n\n\nAF AMER 112A ‚Äì The Sunken Place\n\nFILM TV 183A ‚Äì Film & TV Development\n\nSTATS 141XP ‚Äì Statistics Consulting (Capstone sequence)"
  },
  {
    "objectID": "coursework.html#focus-areas",
    "href": "coursework.html#focus-areas",
    "title": "Coursework",
    "section": "",
    "text": "Statistical Theory & Methods ‚Äì STATS 100A‚ÄìC, 101A‚ÄìC\n\nComputing & Optimization ‚Äì STATS 20, 102A‚ÄìC\n\nApplied & Consulting ‚Äì STATS 101B, 140XP, 141XP\n\nInterdisciplinary Work ‚Äì Data science for social good, digital humanities, film & media, and ethnic studies"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "Projects",
    "section": "",
    "text": "Skin Cancer Classification Prediction\n\n\n\nMachine Learning\n\nPython\n\nHealth\n\n\n\nComparing regularized logistic regression and tree-based models for skin cancer detection.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nStudent Habits & Academic Success\n\n\n\nStatistics\n\nR\n\nEducation\n\n\n\nPredicting academic performance from study habits using R & ML.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFirestorm ‚Äì Visualizing Wildfire Patterns\n\n\n\nData Visualization\n\nGeospatial\n\nTeam Project\n\n\n\nTurning geospatial wildfire data into clear visuals and stories for non-technical audiences.\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Projects/student_habit.html",
    "href": "Projects/student_habit.html",
    "title": "Student Habits & Academic Success",
    "section": "",
    "text": "This project studies how everyday student habits‚Äîlike study time, sleep, screen use, and well-being‚Äîrelate to exam performance. We use a Kaggle dataset of 1,000 students with behavioral and demographic variables and build a regression model to quantify which habits matter most for grades."
  },
  {
    "objectID": "Projects/student_habit.html#goal-research-question",
    "href": "Projects/student_habit.html#goal-research-question",
    "title": "Student Habits & Academic Success",
    "section": "üéØ Goal & Research Question",
    "text": "üéØ Goal & Research Question\n\nGoal: Understand how student lifestyle habits relate to academic success.\nResearch question:\n&gt; ‚ÄúHow do study time, sleep, screen use, and other daily habits affect exam scores?‚Äù"
  },
  {
    "objectID": "Projects/student_habit.html#dataset",
    "href": "Projects/student_habit.html#dataset",
    "title": "Student Habits & Academic Success",
    "section": "üìä Dataset",
    "text": "üìä Dataset\n\nSource: Kaggle ‚ÄúStudent Habits vs Academic Performance‚Äù dataset.\nSample size: 1,000 students\n\nStructure: 16 columns, including:\n\nstudy_hours_per_day\n\nsleep_hours\n\nsocial_media_hours, netflix_hours\n\nexercise_frequency\n\nattendance_percentage\n\ndiet_quality, mental_health_rating\n\nexam_score (target)\n\n\nPre-processing in R:\n\nRemoved student_id\n\nConverted character variables to factors\n\nChecked for missing values"
  },
  {
    "objectID": "Projects/student_habit.html#methods",
    "href": "Projects/student_habit.html#methods",
    "title": "Student Habits & Academic Success",
    "section": "üîß Methods",
    "text": "üîß Methods\nWe modeled exam_score using multiple linear regression.\n\nStarted with all 15 behavioral and demographic predictors.\n\nUsed stepwise selection (stepAIC) to remove insignificant variables and avoid overfitting.\n\nFinal model kept 7 significant predictors:\n\nstudy_hours_per_day\n\nsleep_hours\n\nattendance_percentage\n\nexercise_frequency\n\nmental_health_rating\n\nsocial_media_hours (negative effect)\n\nnetflix_hours (negative effect)\n\n\nTools: R (lm, MASS::stepAIC, broom, ggplot2)."
  },
  {
    "objectID": "Projects/student_habit.html#model-performance-effects",
    "href": "Projects/student_habit.html#model-performance-effects",
    "title": "Student Habits & Academic Success",
    "section": "üìà Model Performance & Effects",
    "text": "üìà Model Performance & Effects\nFrom the final regression model:\n\nAdjusted R¬≤ ‚âà 0.90 ‚Äì the model explains about 90% of the variance in exam scores.\n\nAll predictors in the final model are highly significant (p &lt; 0.001).\n\nLargest effect sizes:\n\n+9.57 exam points per additional hour of study time per day\n\n‚Äì2.62 exam points per additional hour of social media use\n\n‚Äì2.28 exam points per additional hour of Netflix use\n\n\nPositive but smaller contributors:\n\nHigher attendance, more sleep, more exercise, and better mental-health ratings all contribute modestly to higher scores."
  },
  {
    "objectID": "Projects/student_habit.html#key-insights",
    "href": "Projects/student_habit.html#key-insights",
    "title": "Student Habits & Academic Success",
    "section": "üîç Key Insights",
    "text": "üîç Key Insights\n\nStudy time is the strongest positive driver of exam performance.\n\nSleep and mental health matter‚Äîstudents who sleep more and rate their mental health higher tend to do better.\n\nScreen time works against performance, especially social media and Netflix.\n\nAttendance and exercise have smaller but still positive effects."
  },
  {
    "objectID": "Projects/student_habit.html#practical-advice-for-students",
    "href": "Projects/student_habit.html#practical-advice-for-students",
    "title": "Student Habits & Academic Success",
    "section": "‚úÖ Practical Advice for Students",
    "text": "‚úÖ Practical Advice for Students\nBased on our model and exploratory analysis:\n- Boost structured study hours‚Äîeven 1 extra focused hour a day has a big payoff.\n- Aim for 7‚Äì8 hours of sleep to support both grades and mental health.\n- Stay physically active, even in small amounts.\n- Be intentional with screen time, especially social media and streaming.\n- Maintain consistent attendance and prioritize your mental well-being."
  },
  {
    "objectID": "Projects/student_habit.html#project-files",
    "href": "Projects/student_habit.html#project-files",
    "title": "Student Habits & Academic Success",
    "section": "üìÑ Project Files",
    "text": "üìÑ Project Files\n\nüé§ Presentation slides (PDF)\nDownload ‚Üí{Slide}"
  },
  {
    "objectID": "Projects/skin-cancer.html",
    "href": "Projects/skin-cancer.html",
    "title": "Skin Cancer Classification Prediction",
    "section": "",
    "text": "This project builds a model to predict whether a skin lesion is benign or malignant using a 70,000-row synthetic dataset with demographic, environmental, and dermatological features. We compared multiple modeling approaches and ultimately selected GLMNet for its stability, interpretability, and strong generalization.\n\n\n\n\nSkin cancer is among the most common and preventable cancers.\n\nOur task: build a robust classifier that distinguishes benign vs.¬†malignant lesions.\n\nDataset includes both meaningful predictors and intentionally added noise variables.\n\n\n\n\n\n\n70,000 total observations\n49 initial features ‚Üí 36 meaningful after cleaning\nBinary target: benign (0) vs malignant (1)\n\nFeatures include:\n- Lesion size, color, location\n- UV exposure behavior\n- Environment (distance to beach, latitude/longitude)\n- Age, demographics\n- Lifestyle factors (exercise, smoking, diet)\n- 10+ noise variables (favorite_color, phone_brand, etc.)\n\n\n\n\n\n\n\n~8% missing across variables\n\nMedian + mode imputation\n\n\n\n\nDropped intentionally irrelevant variables, like:\nfavorite_color, preferred_cuisine, desk_height_cm, zip_code_last_digit, etc.\n\n\n\nRevealed strong clusters:\n- Lesion features (strongest predictors)\n- Sun exposure patterns\n- Lifestyle variables"
  },
  {
    "objectID": "Projects/skin-cancer.html#problem-context",
    "href": "Projects/skin-cancer.html#problem-context",
    "title": "Skin Cancer Classification Prediction",
    "section": "",
    "text": "Skin cancer is among the most common and preventable cancers.\n\nOur task: build a robust classifier that distinguishes benign vs.¬†malignant lesions.\n\nDataset includes both meaningful predictors and intentionally added noise variables."
  },
  {
    "objectID": "Projects/skin-cancer.html#dataset-overview",
    "href": "Projects/skin-cancer.html#dataset-overview",
    "title": "Skin Cancer Classification Prediction",
    "section": "",
    "text": "70,000 total observations\n49 initial features ‚Üí 36 meaningful after cleaning\nBinary target: benign (0) vs malignant (1)\n\nFeatures include:\n- Lesion size, color, location\n- UV exposure behavior\n- Environment (distance to beach, latitude/longitude)\n- Age, demographics\n- Lifestyle factors (exercise, smoking, diet)\n- 10+ noise variables (favorite_color, phone_brand, etc.)"
  },
  {
    "objectID": "Projects/skin-cancer.html#data-cleaning",
    "href": "Projects/skin-cancer.html#data-cleaning",
    "title": "Skin Cancer Classification Prediction",
    "section": "",
    "text": "~8% missing across variables\n\nMedian + mode imputation\n\n\n\n\nDropped intentionally irrelevant variables, like:\nfavorite_color, preferred_cuisine, desk_height_cm, zip_code_last_digit, etc.\n\n\n\nRevealed strong clusters:\n- Lesion features (strongest predictors)\n- Sun exposure patterns\n- Lifestyle variables"
  },
  {
    "objectID": "Projects/skin-cancer.html#linear-regression-lm",
    "href": "Projects/skin-cancer.html#linear-regression-lm",
    "title": "Skin Cancer Classification Prediction",
    "section": "1. Linear Regression (LM)",
    "text": "1. Linear Regression (LM)\n\nUsed as a baseline even though outcome is binary\n\nProduced poor probability calibration\n\nNot suitable for classification\n‚û°Ô∏è Eliminated immediately"
  },
  {
    "objectID": "Projects/skin-cancer.html#regularized-models",
    "href": "Projects/skin-cancer.html#regularized-models",
    "title": "Skin Cancer Classification Prediction",
    "section": "2. Regularized Models",
    "text": "2. Regularized Models\n\nLasso (L1)\n\nRemoves irrelevant features\n\nGood for high-dimensional noisy data\n\nSlightly unstable across seeds\n\n\n\nRidge (L2)\n\nPenalizes large coefficients\n\nMore stable than Lasso\n\nRetains too many weak predictors\n\n\n\nElastic Net (GLMNet) ‚Äì Final Choice\n\nMix of L1 + L2 regularization\n\nMore stable than Lasso alone\n\nRemoves noise but keeps important correlated features\n\nInterpretable coefficients\n‚û°Ô∏è Chosen model"
  },
  {
    "objectID": "Projects/skin-cancer.html#tree-based-models",
    "href": "Projects/skin-cancer.html#tree-based-models",
    "title": "Skin Cancer Classification Prediction",
    "section": "3. Tree-Based Models",
    "text": "3. Tree-Based Models\n\nRandom Forest\n\nGood accuracy\n\nCaptures non-linear interactions\n\nVery unstable across random seeds\n\nPerformance varied by ¬±5%\n\n\n\nXGBoost\n\nStrong performance after tuning\n\nCaptured complex relationships\n\nOverfitted easily\n\nHarder to interpret\n\n\n\nStacked Trees\n\nBest raw predictive power\n\nMost complex + most unstable\n\nTraining time extremely high\n‚û°Ô∏è Not selected due to instability + interpretability concerns"
  },
  {
    "objectID": "Projects/skin-cancer.html#multi-seed-search-threshold-tuning",
    "href": "Projects/skin-cancer.html#multi-seed-search-threshold-tuning",
    "title": "Skin Cancer Classification Prediction",
    "section": "üé≤ Multi-Seed Search & Threshold Tuning",
    "text": "üé≤ Multi-Seed Search & Threshold Tuning\n\nMulti-seed search\n\nRan the pipeline 40 different times with new random splits\n\nFound a stable seed/configuration\n\nAvoided lucky/unlucky single-split results\n\n\n\nThreshold tuning\n\nDefault cutoff 0.50 was not optimal\n\nTuned threshold from 0.45 ‚Üí 0.55\n\nBest cutoff found: 0.507\n‚û°Ô∏è Slight but meaningful accuracy improvement"
  },
  {
    "objectID": "Projects/skin-cancer.html#limitations",
    "href": "Projects/skin-cancer.html#limitations",
    "title": "Skin Cancer Classification Prediction",
    "section": "‚ö†Ô∏è Limitations",
    "text": "‚ö†Ô∏è Limitations\n\nMedian/mode imputation oversimplifies missingness\n\nSynthetic dataset mixed with noise variables\n\nGLMNet cannot model complex non-linear interactions"
  },
  {
    "objectID": "Projects/skin-cancer.html#takeaways",
    "href": "Projects/skin-cancer.html#takeaways",
    "title": "Skin Cancer Classification Prediction",
    "section": "üß† Takeaways",
    "text": "üß† Takeaways\n\nSimpler models can outperform complex ensembles when stability matters\n\nRegularization is crucial when dealing with noisy, synthetic, or high-dimensional data\n\nTree-based models require careful seed control and tend to be far less reproducible\n\nLesion characteristics dominate all other factors when predicting malignancy"
  },
  {
    "objectID": "Projects/skin-cancer.html#slides",
    "href": "Projects/skin-cancer.html#slides",
    "title": "Skin Cancer Classification Prediction",
    "section": "üé§ Slides",
    "text": "üé§ Slides\nüëâ View Presentation Slides (PDF){Slide}"
  },
  {
    "objectID": "Projects/firestorm.html",
    "href": "Projects/firestorm.html",
    "title": "Firestorm ‚Äì Visualizing Wildfire Patterns",
    "section": "",
    "text": "Our Firestorm project focuses on helping non-technical audiences understand wildfire danger, spread, and impact using clear visuals and maps instead of dense technical reports.\n\n\nView Firestorm Website ‚Üí"
  },
  {
    "objectID": "Projects/firestorm.html#live-website",
    "href": "Projects/firestorm.html#live-website",
    "title": "Firestorm ‚Äì Visualizing Wildfire Patterns",
    "section": "",
    "text": "View Firestorm Website ‚Üí"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Joshua (Xingwang) Zhang",
    "section": "",
    "text": "I‚Äôm an undergraduate Statistics & Data Science student at UCLA who loves turning messy data into clear stories and useful tools. Outside of class, I run an Amazon e-commerce business, manage an Airbnb, and build data-driven dashboards and models for real-world problems.\nWhen I‚Äôm not debugging R or Python, you can probably find me playing basketball, practicing piano or guitar, or testing a new 3D-printed idea."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Joshua (Xingwang) Zhang",
    "section": "Education",
    "text": "Education\nUniversity of California, Los Angeles (UCLA) ¬∑ Los Angeles, CA\nB.S. in Statistics & Data Science ¬∑ Expected June 2026\n- Interests: data science, analytics."
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Joshua (Xingwang) Zhang",
    "section": "Experience",
    "text": "Experience\nHurams Work LLC ¬∑ Co-Founder & Data Analyst ¬∑ 2021 ‚Äì 02/2025\n- Built and scaled an Amazon e-commerce operation (5,000+ orders, six-figure annual revenue).\n- Analyzed sales, pricing, and advertising data in R/Excel to optimize product mix and profits.\n- Designed dashboards to track unit economics, inventory, refunds, and customer satisfaction\n(98%+ positive rating).\n- Coordinated suppliers, logistics, and customer messaging to keep operations smooth.\nAirbnb Host & Operations Analyst ¬∑ 06/2025 ‚Äì 09/2025\n- Manage day-to-day operations for a short-term rental property.\n- Built spreadsheets to track occupancy, pricing, cleaning costs, and repair/claim history.\n- Use data to adjust pricing strategy and improve guest experience and review scores.\nAcademic & Project Work ¬∑ UCLA\n- Collaborate on statistics and data-science projects with classmates from psychology, sociology, and statistics courses.\n- Present data stories using R, Quarto, and BetterPoster-style visualizations."
  },
  {
    "objectID": "index.html#selected-projects",
    "href": "index.html#selected-projects",
    "title": "Joshua (Xingwang) Zhang",
    "section": "Selected Projects",
    "text": "Selected Projects\nStudent Habits & Academic Success: A Behavioral Analysis\n- Modeled the relationship between study habits, sleep, time management, and grades.\n- Used R (tidyverse, ggplot2) for cleaning, EDA, and classification models (logistic / glmnet).\n- Communicated findings in a 6-minute talk with visualizations and an R Quarto report.\nSkin Cancer Classification with Machine Learning\n- Compared regularized logistic regression (lasso/ridge) and tree-based models on image features.\n- Tuned hyperparameters via cross-validation; evaluated with accuracy, ROC curves, and confusion matrices.\nFirestorm: Connecting Wildfire Data to People\n- Built a team website that visualizes fire-pattern and detection data.\n- Focused on making complex spatial data understandable for non-technical audiences using clear charts and explanations."
  },
  {
    "objectID": "index.html#skills",
    "href": "index.html#skills",
    "title": "Joshua (Xingwang) Zhang",
    "section": "Skills",
    "text": "Skills\nProgramming & Tools\nR (tidyverse, ggplot2, caret, glmnet), Python (pandas, NumPy, scikit-learn), SQL, Git/GitHub,\nQuarto, Markdown, Excel/Google Sheets, Tableau/Power BI (familiar), LaTeX/Overleaf (basic).\nData Skills\nData wrangling, feature engineering, exploratory data analysis, visualization, regression and classification models, cross-validation, reporting, and reproducible workflows.\nOther\nProject coordination, small-business operations, customer communication (English & Chinese), presentation and technical writing."
  }
]